{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of subreddit title dataset\n",
    "\n",
    "Goal: Analyzing the subreddit dataset for Structural Balance Theory on longitudinal data setting. We compute the dynamical networks evolving over time and predict its dynamics using SBT with Markov Chain model and Convex optimization estimation method.\n",
    "\n",
    "\n",
    "https://snap.stanford.edu/data/soc-RedditHyperlinks.html\n",
    "\n",
    "The hyperlink network represents the directed connections between two subreddits (a subreddit is a community on Reddit). We also provide subreddit embeddings. The network is extracted from publicly available Reddit data of 2.5 years from Jan 2014 to April 2017.\n",
    "\n",
    "Subreddit Hyperlink Network: the subreddit-to-subreddit hyperlink network is extracted from the posts that create hyperlinks from one subreddit to another. We say a hyperlink originates from a post in the source community and links to a post in the target community. Each hyperlink is annotated with three properties: the timestamp, the sentiment of the source community post towards the target community post, and the text property vector of the source post. The network is directed, signed, temporal, and attributed.\n",
    "\n",
    "Note that each post has a title and a body. The hyperlink can be present in either the title of the post or in the body. Therefore, we provide one network file for each.\n",
    "\n",
    "Subreddit Embeddings: We have also provided embedding vectors representing each subreddit. These can be found in this dataset link: subreddit embedding dataset. Please note that some subreddit embeddings could not be generated, so this file has 51,278 embeddings.\n",
    "\n",
    "Project website: These files have been generated as part of the research project on how subreddits attack one another. The details of the project can be found here.\n",
    "\n",
    "\n",
    "\n",
    "Dataset statistics\n",
    "Number of nodes (subreddits)\t55,863\n",
    "Number of edges (hyperlink between subreddits)\t858,490\n",
    "Edge weights (label of hyperlink)\t-1 or +1\n",
    "Edge attributes\tText property vectors\n",
    "Timespan\tJan 2014 - April 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from time import time\n",
    "from typing import Text\n",
    "import collections\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import imp\n",
    "import os\n",
    "import pickle as pk\n",
    "from pyvis.network import Network\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../src/')\n",
    "\n",
    "import network_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload():\n",
    "    imp.reload(network_utils)\n",
    "    imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer():\n",
    "    def __init__(self, message: Text = None):\n",
    "        if message:\n",
    "            self.message = message\n",
    "        else:\n",
    "            self.message = 'It took {elapsed_time:.2f} {unit}.'\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "        return None\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        elapsed_time = time() - self.start\n",
    "        if elapsed_time < 60:\n",
    "            unit = 'seconds'\n",
    "        elif elapsed_time < 3600:\n",
    "            unit = 'minutes'\n",
    "            elapsed_time /= 60.0\n",
    "        else:\n",
    "            unit = 'hours'\n",
    "            elapsed_time /= 3600.0\n",
    "        print(\n",
    "            self.message.format(elapsed_time=elapsed_time, unit=unit))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dataset_file_path = '/home/omid/Datasets/Subreddit/soc-redditHyperlinks-title.tsv'\n",
    "weeks = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(title_dataset_file_path, sep='\\t')\n",
    "data['TIMESTAMP'] = pd.to_datetime(data['TIMESTAMP'])\n",
    "data.rename(\n",
    "    columns={\n",
    "        'TIMESTAMP': 'edge_date',\n",
    "        'SOURCE_SUBREDDIT': 'source',\n",
    "        'TARGET_SUBREDDIT': 'target',\n",
    "        'LINK_SENTIMENT': 'weight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Edges signs are: ', np.unique(data['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('How many edges are given from a source to target more than once over time: ',\n",
    "      len(np.where(data[['source', 'target']].duplicated())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = len(data)\n",
    "print('Data has {} #edges.\\nIt spans from {} to {}.\\n'\n",
    "      'It has {} #nodes (unique) in total duration.'.format(\n",
    "          data_len,\n",
    "          min(data['edge_date']),\n",
    "          max(data['edge_date']),\n",
    "          len(set(data['source']).union(set(data['target'])))))\n",
    "\n",
    "pos = len(np.where(data['weight'] > 0)[0])\n",
    "neg = len(np.where(data['weight'] < 0)[0])\n",
    "zer = len(np.where(data['weight'] == 0)[0])  # It should not be any zeros.\n",
    "print('\\nEdge over time:\\n\\t+:'\n",
    "      ' {}({}%)\\n\\t-: {}({}%)\\n\\t0: {}({}%).'.format(\n",
    "          pos, round(100*pos/data_len),\n",
    "          neg, round(100*neg/data_len),\n",
    "          zer, round(100*zer/data_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['weight']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer():\n",
    "    separate_dgraphs = network_utils.extract_graphs(edge_list=data, weeks=weeks, accumulative=False, sum_multiple_edge=True)\n",
    "    accumulative_dgraphs = network_utils.extract_graphs(edge_list=data, weeks=weeks, accumulative=True, sum_multiple_edge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the networks.\n",
    "with open('/home/omid/Datasets/Subreddit/networks_avg.pkl', 'wb') as f:\n",
    "    pk.dump({'separate_dgraphs': separate_dgraphs, 'accumulative_dgraphs': accumulative_dgraphs}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(8, 8)})\n",
    "G = separate_dgraphs[0]\n",
    "\n",
    "colors = []\n",
    "for edge in G.edges():\n",
    "    weight = G.get_edge_data(edge[0], edge[1])['weight']\n",
    "    if weight == 0:\n",
    "        colors.append('b')\n",
    "    elif weight > 0:\n",
    "        colors.append('g')\n",
    "    else:\n",
    "        colors.append('r')\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=30,\n",
    "                       node_color='k',\n",
    "                       cmap=plt.cm.Greys)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5, edge_color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = Network(directed=True, notebook=True)\n",
    "G.from_nx(separate_dgraphs[0])\n",
    "G.show_buttons(filter_=['physics'])\n",
    "G.show(\"mygraph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just to create title names.\n",
    "title_names = []\n",
    "start_date = min(data['edge_date'])\n",
    "end_date = max(data['edge_date'])\n",
    "periods_num = int(np.floor((end_date - start_date).days / (weeks * 7)))\n",
    "for period_index in range(periods_num):\n",
    "    period_start = (\n",
    "        start_date + period_index * datetime.timedelta(weeks * 7))\n",
    "    period_end = period_start + datetime.timedelta(weeks * 7)\n",
    "    title_names.append('{} to {}'.format(period_start, period_end))\n",
    "\n",
    "network_utils.plot_evolving_graphs(dgraphs=separate_dgraphs, titles=title_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the metrics for networks in periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for separate dynamic graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = sorted(\n",
    "    network_utils.get_metrics_for_network(separate_dgraphs[0]).keys())\n",
    "\n",
    "evolving_metrics = collections.defaultdict(list)\n",
    "for index, directed_graph in enumerate(separate_dgraphs):\n",
    "    print(index, '...')\n",
    "    metrics = network_utils.get_metrics_for_network(directed_graph)\n",
    "    for key in sorted_keys:\n",
    "        evolving_metrics[key].append(metrics[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 6\n",
    "n = 5\n",
    "sns.set(rc={'figure.figsize':(25, 30)})\n",
    "\n",
    "sorted_keys = sorted(list(\n",
    "    set(evolving_metrics.keys()) - set([\n",
    "        '#pos edges', '#neg edges', '#gcc pos edges', '#gcc neg edges'])))\n",
    "\n",
    "plt.subplot(m, n, 1)\n",
    "plt.plot(evolving_metrics['#pos edges'], 'g')\n",
    "plt.plot(evolving_metrics['#neg edges'], 'r')\n",
    "plt.xlabel('#edges')\n",
    "plt.legend(['pos', 'neg'])\n",
    "\n",
    "plt.subplot(m, n, 2)\n",
    "plt.plot(evolving_metrics['#gcc pos edges'], 'g')\n",
    "plt.plot(evolving_metrics['#gcc neg edges'], 'r')\n",
    "plt.xlabel('#gcc edges')\n",
    "plt.legend(['pos', 'neg'])\n",
    "\n",
    "for index, key in enumerate(sorted_keys):\n",
    "    plt.subplot(m, n, index+3)\n",
    "    plt.plot(evolving_metrics[key])\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for accumulative dynamic graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = sorted(\n",
    "    network_utils.get_metrics_for_network(accumulative_dgraphs[0]).keys())\n",
    "\n",
    "accumulative_evolving_metrics = collections.defaultdict(list)\n",
    "for index, accumulative_dgraph in enumerate(accumulative_dgraphs):\n",
    "    print(index, '...')\n",
    "    metrics = network_utils.get_metrics_for_network(accumulative_dgraph)\n",
    "    for key in sorted_keys:\n",
    "        accumulative_evolving_metrics[key].append(metrics[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 6\n",
    "n = 5\n",
    "sns.set(rc={'figure.figsize':(25, 30)})\n",
    "\n",
    "sorted_keys = sorted(list(\n",
    "    set(accumulative_evolving_metrics.keys()) - set([\n",
    "        '#pos edges', '#neg edges', '#gcc pos edges', '#gcc neg edges'])))\n",
    "\n",
    "plt.subplot(m, n, 1)\n",
    "plt.plot(accumulative_evolving_metrics['#pos edges'], 'g')\n",
    "plt.plot(accumulative_evolving_metrics['#neg edges'], 'r')\n",
    "plt.xlabel('#edges')\n",
    "plt.legend(['pos', 'neg'])\n",
    "\n",
    "plt.subplot(m, n, 2)\n",
    "plt.plot(accumulative_evolving_metrics['#gcc pos edges'], 'g')\n",
    "plt.plot(accumulative_evolving_metrics['#gcc neg edges'], 'r')\n",
    "plt.xlabel('#gcc edges')\n",
    "plt.legend(['pos', 'neg'])\n",
    "\n",
    "for index, key in enumerate(sorted_keys):\n",
    "    plt.subplot(m, n, index+3)\n",
    "    plt.plot(accumulative_evolving_metrics[key])\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "edge_balances = []\n",
    "for separate_dgraph in separate_dgraphs:\n",
    "    edge_balances.append(\n",
    "        network_utils.compute_edge_balance(separate_dgraph))\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print('It took :', duration/60, 'mins.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4\n",
    "n = 4\n",
    "sns.set(rc={'figure.figsize':(20, 20)})\n",
    "for index, edge_balance in enumerate(edge_balances):\n",
    "    num_unbalanced = []\n",
    "    for value in edge_balance.values():\n",
    "        num_unbalanced.append(\n",
    "            value['#cycle3'] - value['#balanced'])\n",
    "    plt.subplot(m, n, index + 1)\n",
    "    if num_unbalanced:\n",
    "        num_unbalanced = np.array(num_unbalanced)\n",
    "        num_unbalanced = num_unbalanced[num_unbalanced.nonzero()]\n",
    "    plt.hist(num_unbalanced)\n",
    "    \n",
    "    # Period.\n",
    "    period_start = (\n",
    "        start_date + index * datetime.timedelta(weeks * 7))\n",
    "    period_end = period_start + datetime.timedelta(weeks * 7)\n",
    "    plt.title(\n",
    "        '{} to {}'.format(str(period_start).split(' ')[0],\n",
    "                          str(period_end).split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_balance = collections.defaultdict(list)\n",
    "# transitions_div_unbalance = collections.defaultdict(list)\n",
    "for edge_balance in edge_balances:\n",
    "    for key, value in edge_balance.items():\n",
    "        transitions_balance[key].append(value['#balanced']/value['#cycle3'])\n",
    "#         transitions_div_unbalance[key].append(1 - value['#balanced'] / value['#cycle3'])\n",
    "\n",
    "\n",
    "balanced_cycle3_ratio = []\n",
    "for val in transitions_balance.values():\n",
    "    if len(val) > 12:\n",
    "        balanced_cycle3_ratio.append(val)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8, 8)})\n",
    "balanced_cycle3_ratio = np.array(balanced_cycle3_ratio)\n",
    "n, m =balanced_cycle3_ratio.shape\n",
    "plt.errorbar(x=np.arange(0, m),\n",
    "             y=np.mean(balanced_cycle3_ratio, axis=0),\n",
    "             yerr=np.std(balanced_cycle3_ratio, axis=0)/np.sqrt(n));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulative graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulative_edge_balances = []\n",
    "for accumulative_dgraph in accumulative_dgraphs:\n",
    "    accumulative_edge_balances.append(\n",
    "        network_utils.compute_edge_balance(accumulative_dgraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = 4\n",
    "n = 4\n",
    "sns.set(rc={'figure.figsize':(20, 20)})\n",
    "for index, accumulative_edge_balance in enumerate(accumulative_edge_balances):\n",
    "    num_unbalanced = []\n",
    "    for value in accumulative_edge_balance.values():\n",
    "        num_unbalanced.append(\n",
    "            value['#cycle3'] - value['#balanced'])\n",
    "    plt.subplot(m, n, index + 1)\n",
    "    if num_unbalanced:\n",
    "        num_unbalanced = np.array(num_unbalanced)\n",
    "        num_unbalanced = num_unbalanced[num_unbalanced.nonzero()]\n",
    "    plt.hist(num_unbalanced)\n",
    "    \n",
    "    # Period.\n",
    "    period_start = (\n",
    "        start_date + index * datetime.timedelta(weeks * 7))\n",
    "    period_end = period_start + datetime.timedelta(weeks * 7)\n",
    "    plt.title(\n",
    "        '{} to {}'.format(str(period_start).split(' ')[0],\n",
    "                          str(period_end).split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_transitions_balance = collections.defaultdict(list)\n",
    "for accumulative_edge_balance in accumulative_edge_balances:\n",
    "    for key, value in accumulative_edge_balance.items():\n",
    "        acc_transitions_balance[key].append(value['#balanced'] / value['#cycle3'])\n",
    "\n",
    "acc_balanced_cycle3_ratio = []\n",
    "for val in acc_transitions_balance.values():\n",
    "    if len(val) > 12:\n",
    "        acc_balanced_cycle3_ratio.append(val)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8, 8)})\n",
    "acc_balanced_cycle3_ratio = np.array(acc_balanced_cycle3_ratio)\n",
    "n, m = acc_balanced_cycle3_ratio.shape\n",
    "plt.errorbar(x=np.arange(0, m),\n",
    "             y=np.mean(acc_balanced_cycle3_ratio, axis=0),\n",
    "             yerr=np.std(acc_balanced_cycle3_ratio, axis=0)/np.sqrt(n));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain of Sparse Triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triad_map, triad_list = network_utils.generate_all_possible_sparse_triads()\n",
    "unique_triad_num = len(triad_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer():\n",
    "    result = network_utils.compute_transition_matrix(\n",
    "        dgraphs=separate_dgraphs,\n",
    "        unique_triad_num=unique_triad_num,\n",
    "        triad_map=triad_map,\n",
    "        verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the transitions.\n",
    "with open('/local/home/student/omid55/sbt_data_saved/transitions_avg.pkl', 'wb') as f:\n",
    "    pk.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for transition_matrix in result['transition_matrices']:\n",
    "    sns.set(rc={'figure.figsize': (10, 10)})\n",
    "    print('Nonzero percentage: ', round(100 * len(np.where(transition_matrix > 0)[0]) / (unique_triad_num * unique_triad_num), 2), '%')\n",
    "    sns.heatmap(transition_matrix, cmap=\"YlGnBu\", linewidths=.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for transition_matrix in result['transition_matrices']:\n",
    "#     sns.set(rc={'figure.figsize': (8, 8)})\n",
    "#     plt.plot(np.sum(transition_matrix, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (8, 8)})\n",
    "for transition_matrix in result['transition_matrices']:\n",
    "    st_dist = network_utils.get_stationary_distribution(transition_matrix)\n",
    "    plt.plot(st_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_transition_matrix = np.zeros(\n",
    "    (unique_triad_num, unique_triad_num))\n",
    "std_transition_matrix = np.zeros(\n",
    "    (unique_triad_num, unique_triad_num))\n",
    "for i in range(unique_triad_num):\n",
    "    for j in range(unique_triad_num):\n",
    "        item_ij = []\n",
    "        for matrix in result['transition_matrices']:\n",
    "            item_ij.append(matrix[i, j])\n",
    "        mean_transition_matrix[i, j] = np.mean(item_ij)\n",
    "        std_transition_matrix[i, j] = np.std(item_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (20, 20)})\n",
    "sns.heatmap(mean_transition_matrix, cmap=\"YlGnBu\", linewidths=.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (20, 20)})\n",
    "sns.heatmap(std_transition_matrix, cmap=\"YlGnBu\", linewidths=.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (8, 8)})\n",
    "st_dist = network_utils.get_stationary_distribution(mean_transition_matrix)\n",
    "plt.plot(st_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.where(st_dist >= np.mean(st_dist))[0]:\n",
    "    print(triad_list[index])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulated graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "acc_result = network_utils.compute_transition_matrix(\n",
    "    dgraphs=accumulative_dgraphs,\n",
    "    unique_triad_num=unique_triad_num,\n",
    "    triad_map=triad_map,\n",
    "    verbose=True)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print('It took :', duration/60, 'mins.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the accumulative transitions.\n",
    "with open('/local/home/student/omid55/sbt_data_saved/acc_transitions_avg.pkl', 'wb') as f:\n",
    "    pk.dump(acc_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for transition_matrix in acc_result['transition_matrices']:\n",
    "    sns.set(rc={'figure.figsize': (10, 10)})\n",
    "    print('Nonzero percentage: ', round(100 * len(np.where(transition_matrix > 0)[0]) / (unique_triad_num * unique_triad_num), 2), '%')\n",
    "    sns.heatmap(transition_matrix, cmap=\"YlGnBu\", linewidths=.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for transition_matrix in acc_result['transition_matrices']:\n",
    "#     sns.set(rc={'figure.figsize': (8, 8)})\n",
    "#     plt.plot(np.sum(transition_matrix, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (10, 10)})\n",
    "st_dists = []\n",
    "for transition_matrix in acc_result['transition_matrices']:\n",
    "    st_dist = network_utils.get_stationary_distribution(transition_matrix)\n",
    "    st_dists.append(st_dist)\n",
    "    plt.plot(st_dist)\n",
    "# plt.legend(['P'+str(i) for i in range(1, 1+len(acc_result['transition_matrices']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mean_transition_matrix = np.zeros(\n",
    "    (unique_triad_num, unique_triad_num))\n",
    "acc_std_transition_matrix = np.zeros(\n",
    "    (unique_triad_num, unique_triad_num))\n",
    "for i in range(unique_triad_num):\n",
    "    for j in range(unique_triad_num):\n",
    "        item_ij = []\n",
    "        for matrix in acc_result['transition_matrices']:\n",
    "            item_ij.append(matrix[i, j])\n",
    "        acc_mean_transition_matrix[i, j] = np.mean(item_ij)\n",
    "        acc_std_transition_matrix[i, j] = np.std(item_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (20, 20)})\n",
    "sns.heatmap(acc_mean_transition_matrix, cmap=\"YlGnBu\", linewidths=.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (20, 20)})\n",
    "sns.heatmap(acc_std_transition_matrix, cmap=\"YlGnBu\", linewidths=.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (8, 8)})\n",
    "acc_st_dist = network_utils.get_stationary_distribution(acc_mean_transition_matrix)\n",
    "plt.plot(acc_st_dist, 'p');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.where(acc_st_dist >= 0.06)[0]:\n",
    "    print(triad_list[index])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index in np.where(acc_st_dist >= np.mean(acc_st_dist))[0]:\n",
    "    print(triad_list[index])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex estimating the transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_of_138(a):\n",
    "    r = a\n",
    "    if len(a) < 138:\n",
    "        r = np.array(list(a) + [0 for i in range(138 - len(a))])\n",
    "    return r\n",
    "\n",
    "def get_matrix_stochastic(a):\n",
    "    a = a / np.sum(a)\n",
    "    return np.matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 40\n",
    "loaded_d = utils.load_it('/home/omid/Downloads/DT/cvx_data.pk')\n",
    "obs = loaded_d['obs']\n",
    "T = loaded_d['T']\n",
    "\n",
    "obs_mat = []\n",
    "for o in obs:\n",
    "    obs_mat.append(np.matrix(o))\n",
    "    \n",
    "obs_normalized = []\n",
    "for o in obs:\n",
    "    obs_normalized.append(get_matrix_stochastic(o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# # l = 103\n",
    "# n = 138\n",
    "# lam1 = 0.4\n",
    "# lam2 = 0.2\n",
    "# lam3 = 0.1\n",
    "# lam4 = 0.1\n",
    "\n",
    "# # Variables.\n",
    "# M = [cp.Variable(n, n) for _ in range(l-1)]\n",
    "\n",
    "# # Objective function.\n",
    "# term1 = 0\n",
    "# for i in range(l-1):\n",
    "# #     term1 += cp.norm2(obs_mat[i] * M[i] - obs_mat[i + 1])\n",
    "#     term1 += cp.norm2(obs_normalized[i] * M[i] - obs_normalized[i + 1])\n",
    "\n",
    "# term2 = 0\n",
    "# for i in range(1, l-1):\n",
    "#     term2 += cp.norm2(M[i] - M[i - 1])\n",
    "# term2 *= lam1\n",
    "\n",
    "# term3 = 0\n",
    "# for i in range(1, l-1):\n",
    "#     term3 += cp.norm1(M[i] - M[i - 1])\n",
    "# term3 *= lam2\n",
    "\n",
    "# # term3 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term3 += cp.norm2(M[i] - T[i])\n",
    "# # term3 *= lam2\n",
    "\n",
    "# # term4 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term4 += cp.norm1(M[i])\n",
    "# # term4 *= lam3\n",
    "\n",
    "# # term5 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term5 += cp.norm_nuc.normNuc(M[i])\n",
    "# # term5 *= lam4\n",
    "\n",
    "# objective = cp.Minimize(term1 + term2 + term3) #+ term4) # + term5)\n",
    "\n",
    "# # Constraints.\n",
    "# constraints = []\n",
    "# for i in range(l-1):\n",
    "#     constraints += (\n",
    "#         [0 <= M[i],\n",
    "#          M[i] <= 1,\n",
    "#          M[i] * np.ones(n) == np.ones(n)])\n",
    "# #          obs_normalized[i + 1] * M[i] == obs_normalized[i + 1]])\n",
    "    \n",
    "# # Problem.\n",
    "# prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# # Solving the problem.\n",
    "# # res = prob.solve(cp.SCS)\n",
    "# # res = prob.solve(cp.CVXOPT)\n",
    "# res = prob.solve(cp.MOSEK)\n",
    "# # res = prob.solve()\n",
    "# print(res)\n",
    "\n",
    "# duration = time.time() - start_time\n",
    "# print('It took :{} mins.'.format(round(duration/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# # l = 103\n",
    "# n = 138\n",
    "# lam1 = 0.4\n",
    "# lam2 = 0.2\n",
    "# lam3 = 0.1\n",
    "# lam4 = 0.1\n",
    "\n",
    "# # Variables.\n",
    "# M = [cp.Variable(n, n) for _ in range(l-1)]\n",
    "\n",
    "# # Objective function.\n",
    "# term1 = 0\n",
    "# for i in range(l-1):\n",
    "# #     term1 += cp.norm2(obs_mat[i] * M[i] - obs_mat[i + 1])\n",
    "#     term1 += cp.norm2(obs_normalized[i] * M[i] - obs_normalized[i + 1])\n",
    "\n",
    "# term2 = 0\n",
    "# for i in range(1, l-1):\n",
    "#     term2 += cp.norm1(M[i] - M[i - 1])\n",
    "# term2 *= lam1\n",
    "\n",
    "# # term3 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term3 += cp.norm2(M[i] - T[i])\n",
    "# # term3 *= lam2\n",
    "\n",
    "# # term4 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term4 += cp.norm1(M[i])\n",
    "# # term4 *= lam3\n",
    "\n",
    "# # term5 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term5 += cp.norm_nuc.normNuc(M[i])\n",
    "# # term5 *= lam4\n",
    "\n",
    "# objective = cp.Minimize(term1 + term2) #+ term3) #+ term4) # + term5)\n",
    "\n",
    "# # Constraints.\n",
    "# constraints = []\n",
    "# for i in range(l-1):\n",
    "#     constraints += (\n",
    "#         [0 <= M[i],\n",
    "#          M[i] <= 1,\n",
    "#          M[i] * np.ones(n) == np.ones(n)])\n",
    "# #          obs_normalized[i + 1] * M[i] == obs_normalized[i + 1]])\n",
    "    \n",
    "# # Problem.\n",
    "# prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# # Solving the problem.\n",
    "# # res = prob.solve(cp.SCS)\n",
    "# # res = prob.solve(cp.CVXOPT)\n",
    "# res = prob.solve(cp.MOSEK)\n",
    "# # res = prob.solve()\n",
    "# print(res)\n",
    "\n",
    "# duration = time.time() - start_time\n",
    "# print('It took :{} mins.'.format(round(duration/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# # l = 103\n",
    "# n = 138\n",
    "# lam1 = 0.4\n",
    "# lam2 = 0.2\n",
    "# lam3 = 0.1\n",
    "# lam4 = 0.1\n",
    "\n",
    "# # Variables.\n",
    "# M = [cp.Variable(n, n) for _ in range(l-1)]\n",
    "\n",
    "# # Objective function.\n",
    "# term1 = 0\n",
    "# for i in range(l-1):\n",
    "# #     term1 += cp.norm2(obs_mat[i] * M[i] - obs_mat[i + 1])\n",
    "#     term1 += cp.norm2(obs_normalized[i] * M[i] - obs_normalized[i + 1])\n",
    "\n",
    "# term2 = 0\n",
    "# for i in range(1, l-1):\n",
    "#     term2 += cp.norm2(M[i] - M[i - 1])\n",
    "# term2 *= lam1\n",
    "\n",
    "# # term3 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term3 += cp.norm2(M[i] - T[i])\n",
    "# # term3 *= lam2\n",
    "\n",
    "# # term4 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term4 += cp.norm1(M[i])\n",
    "# # term4 *= lam3\n",
    "\n",
    "# # term5 = 0\n",
    "# # for i in range(l-1):\n",
    "# #     term5 += cp.norm_nuc.normNuc(M[i])\n",
    "# # term5 *= lam4\n",
    "\n",
    "# objective = cp.Minimize(term1 + term2) #+ term3) #+ term4) # + term5)\n",
    "\n",
    "# # Constraints.\n",
    "# constraints = []\n",
    "# for i in range(l-1):\n",
    "#     constraints += (\n",
    "#         [0 <= M[i],\n",
    "#          M[i] <= 1,\n",
    "#          M[i] * np.ones(n) == np.ones(n),\n",
    "#          obs_normalized[i + 1] * M[i] == obs_normalized[i + 1]])\n",
    "    \n",
    "# # Problem.\n",
    "# prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# # Solving the problem.\n",
    "# # res = prob.solve(cp.SCS)\n",
    "# # res = prob.solve(cp.CVXOPT)\n",
    "# res = prob.solve(cp.MOSEK)\n",
    "# # res = prob.solve()\n",
    "# print(res)\n",
    "\n",
    "# duration = time.time() - start_time\n",
    "# print('It took :{} mins.'.format(round(duration/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# l = 103\n",
    "n = 138\n",
    "lam1 = 0.4\n",
    "lam2 = 0.2\n",
    "lam3 = 0.1\n",
    "lam4 = 0.1\n",
    "\n",
    "# Variables.\n",
    "M = [cp.Variable(n, n) for _ in range(l-1)]\n",
    "\n",
    "# Objective function.\n",
    "term1 = 0\n",
    "for i in range(l-1):\n",
    "#     term1 += cp.norm2(obs_mat[i] * M[i] - obs_mat[i + 1])\n",
    "    term1 += cp.norm2(obs_normalized[i] * M[i] - obs_normalized[i + 1])\n",
    "\n",
    "term2 = 0\n",
    "for i in range(1, l-1):\n",
    "    term2 += cp.norm1(M[i] - M[i - 1])\n",
    "term2 *= lam1\n",
    "\n",
    "# term3 = 0\n",
    "# for i in range(l-1):\n",
    "#     term3 += cp.norm2(M[i] - T[i])\n",
    "# term3 *= lam2\n",
    "\n",
    "# term4 = 0\n",
    "# for i in range(l-1):\n",
    "#     term4 += cp.norm1(M[i])\n",
    "# term4 *= lam3\n",
    "\n",
    "# term5 = 0\n",
    "# for i in range(l-1):\n",
    "#     term5 += cp.norm_nuc.normNuc(M[i])\n",
    "# term5 *= lam4\n",
    "\n",
    "objective = cp.Minimize(term1 + term2) #+ term3) # + term5)\n",
    "\n",
    "# Constraints.\n",
    "constraints = []\n",
    "for i in range(l-1):\n",
    "    constraints += (\n",
    "        [0 <= M[i],\n",
    "         M[i] <= 1,\n",
    "         M[i] * np.ones(n) == np.ones(n)])\n",
    "    \n",
    "# Problem.\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# Solving the problem.\n",
    "# res = prob.solve(cp.SCS)\n",
    "# res = prob.solve(cp.CVXOPT)\n",
    "res = prob.solve(cp.MOSEK)\n",
    "# res = prob.solve()\n",
    "print(res)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print('It took :{} mins.'.format(round(duration/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "for i in range(1, l-1):\n",
    "    diff.append(np.linalg.norm(M[i].value - M[i-1].value))\n",
    "plt.plot(diff);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitives = []\n",
    "for triad in triad_list:\n",
    "    transitives.append(network_utils.is_sparsely_transitive_balanced(triad))\n",
    "transitives = np.array(transitives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = []\n",
    "for triad in triad_list:\n",
    "    ch.append(network_utils.is_sparsely_cartwright_harary_balanced(triad))\n",
    "ch = np.array(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_transitive_means = []\n",
    "self_nontransitive_means = []\n",
    "nontransitive_to_transitive_means = []\n",
    "transitive_to_nontransitive_means = []\n",
    "self_transitive_stds = []\n",
    "self_nontransitive_stds = []\n",
    "nontransitive_to_transitive_stds = []\n",
    "transitive_to_nontransitive_stds = []\n",
    "\n",
    "for matrix in M:\n",
    "    trans_matrix = matrix.value\n",
    "    \n",
    "    probs = np.sum(trans_matrix[transitives, :][:, transitives], axis=1)\n",
    "    self_transitive_means.append(np.mean(probs))\n",
    "    self_transitive_stds.append(np.std(probs))\n",
    "\n",
    "    probs = np.sum(trans_matrix[~transitives, :][:, transitives], axis=1)\n",
    "    nontransitive_to_transitive_means.append(np.mean(probs))\n",
    "    nontransitive_to_transitive_stds.append(np.std(probs))\n",
    "\n",
    "    probs = np.sum(trans_matrix[~transitives, :][:, ~transitives], axis=1)\n",
    "    transitive_to_nontransitive_means.append(np.mean(probs))\n",
    "    transitive_to_nontransitive_stds.append(np.std(probs))\n",
    "\n",
    "    probs = np.sum(trans_matrix[transitives, :][:, ~transitives], axis=1)\n",
    "    self_nontransitive_means.append(np.mean(probs))\n",
    "    self_nontransitive_stds.append(np.std(probs))\n",
    "    \n",
    "\n",
    "plt.errorbar(x=np.arange(l-1), y=self_transitive_means, yerr=self_transitive_stds, fmt='r')\n",
    "plt.errorbar(x=np.arange(l-1), y=nontransitive_to_transitive_means, yerr=nontransitive_to_transitive_stds, fmt='g')\n",
    "plt.errorbar(x=np.arange(l-1), y=self_nontransitive_means, yerr=self_nontransitive_stds, fmt='b')\n",
    "plt.errorbar(x=np.arange(l-1), y=transitive_to_nontransitive_means, yerr=transitive_to_nontransitive_stds, fmt='k')\n",
    "plt.legend(['self transitive', 'nontransitive to transitive', 'self nontransitive', 'transitive to nontransitive']);\n",
    "\n",
    "\n",
    "# plt.errorbar(x=np.arange(39), y=self_transitive_means) #, yerr=self_transitive_stds)\n",
    "# plt.errorbar(x=np.arange(39), y=nontransitive_to_transitive_means) #, yerr=nontransitive_to_transitive_stds)\n",
    "# plt.errorbar(x=np.arange(39), y=self_nontransitive_means) #, yerr=self_nontransitive_stds)\n",
    "# plt.errorbar(x=np.arange(39), y=transitive_to_nontransitive_means) #, yerr=transitive_to_nontransitive_stds)\n",
    "# plt.legend(['self transitive', 'nontransitive to transitive', 'self nontransitive', 'transitive to nontransitive']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting future of each edge with respect to all triads that is involved in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_index = 0\n",
    "\n",
    "dgraph = separate_dgraphs[period_index]\n",
    "nodes = dgraph.nodes()\n",
    "for edge in dgraph.edges():\n",
    "    rest_of_nodes = list(set(nodes) - set(edge))\n",
    "    for node in rest_of_nodes:\n",
    "        triad_type = result['triads_types'][period_index][str(tuple(sorted([edge[0], edge[1], node])))]\n",
    "        prob = result['transition_matrices'][period_index][triad_type, :]\n",
    "        print(prob)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting future transition and ratio of triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_index = 0\n",
    "\n",
    "matrix = acc_result['transition_matrices'][period_index]\n",
    "triad_count = np.bincount(list(result['triads_types'][period_index].values()), minlength=138)\n",
    "triad_count = triad_count / np.sum(triad_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_period_count = np.squeeze(np.asarray(np.matrix(triad_count) * np.matrix(matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_triad_count = np.bincount(list(result['triads_types'][period_index+1].values()), minlength=138)\n",
    "next_triad_count = next_triad_count / np.sum(next_triad_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (8, 8)})\n",
    "plt.plot(np.array(abs(predicted_period_count - next_triad_count)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries prediction for transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (100, 100)})\n",
    "sns.set(font_scale=0.25)\n",
    "c = 0\n",
    "for i in range(unique_triad_num):\n",
    "    for j in range(unique_triad_num):\n",
    "        c += 1\n",
    "        item_ij = []\n",
    "        for matrix in result['transition_matrices']:\n",
    "            item_ij.append(matrix[i, j])\n",
    "        plt.subplot(unique_triad_num, unique_triad_num, c)\n",
    "        plt.plot(item_ij)\n",
    "        if c > 139:\n",
    "            break\n",
    "    if c > 139:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng = 4\n",
    "\n",
    "rmses = 0\n",
    "errors = {}\n",
    "for i in range(unique_triad_num):\n",
    "    for j in range(unique_triad_num):\n",
    "        item_ij = []\n",
    "        for matrix in result['transition_matrices']:\n",
    "            item_ij.append(matrix[i, j])\n",
    "        # Timeseries forecasting.\n",
    "        model = ARIMA(item_ij[:-leng], order=(2, 1, 0))\n",
    "        model = model.fit()\n",
    "        rmse = sqrt(mean_squared_error(item_ij[-leng:], model.forecast(steps=leng)[0]))\n",
    "        errors[str((i, j))] = rmse\n",
    "        rmses += rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses / (unique_triad_num * unique_triad_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only for one item in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "item_ij = []\n",
    "for matrix in result['transition_matrices']:\n",
    "    item_ij.append(matrix[i, j])\n",
    "# Timeseries forecasting.\n",
    "model = ARIMA(item_ij[:-leng], order=(2, 1, 0))\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(item_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fit.summary())\n",
    "# plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "plt.show()\n",
    "residuals.plot(kind='kde')\n",
    "plt.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual = item_ij[-leng:] - fitted_model.forecast(steps=leng)[0]\n",
    "# rmse = sqrt(mean_squared_error(item_ij[-leng:], fitted_model.forecast(steps=leng)[0]))\n",
    "# print('RMSE: ', rmse)\n",
    "# plt.plot(residual);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(pd.rolling_mean(pd.DataFrame(item_ij), window=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(pd.rolling_std(pd.DataFrame(item_ij), window=12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartwright & Harary balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for separate_dgraph in separate_dgraphs:\n",
    "#     print('cartwright & harary unbalance ratio: ',\n",
    "#           network_utils.cartwright_harary_balance(separate_dgraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How transition matrices change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = network_utils.get_just_periods(edge_list=data, weeks=weeks, accumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-nrom distance of each matrix from the average transition matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (60, 20)})\n",
    "l2norm_dists = []\n",
    "for matrix in result['transition_matrices']:\n",
    "    l2norm_dists.append(np.linalg.norm(matrix - mean_transition_matrix))\n",
    "plt.plot(l2norm_dists)\n",
    "plt.ylabel('L2-norm distance from average transition matrix.')\n",
    "# seting xticks\n",
    "ax = plt.axes()\n",
    "number_of_periods = len(periods)\n",
    "ax.set_xticks(list(range(number_of_periods)))\n",
    "labels = ['[{}, {}] to [{}, {}]'.format(periods[i][0][:7], periods[i][1][:7], periods[i+1][0][:7], periods[i+1][1][:7]) for i in range(number_of_periods-1)]\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (60, 20)})\n",
    "acc_l2norm_dists = []\n",
    "for matrix in acc_result['transition_matrices']:\n",
    "    acc_l2norm_dists.append(np.linalg.norm(matrix - acc_mean_transition_matrix))\n",
    "plt.plot(acc_l2norm_dists)\n",
    "plt.ylabel('L2-norm distance from average transition matrix.')\n",
    "# seting xticks\n",
    "ax = plt.axes()\n",
    "number_of_periods = len(periods)\n",
    "ax.set_xticks(list(range(number_of_periods)))\n",
    "labels = ['[{}, {}] to [{}, {}]'.format(periods[i][0][:7], periods[i][1][:7], periods[i+1][0][:7], periods[i+1][1][:7]) for i in range(number_of_periods-1)]\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-nrom distance of each matrix from its previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (60, 20)})\n",
    "from_prev_l2norm_dists = []\n",
    "n = len(result['transition_matrices'])\n",
    "for i in range(1, n):\n",
    "    current = result['transition_matrices'][i]\n",
    "    prev = result['transition_matrices'][i-1]\n",
    "    from_prev_l2norm_dists.append(np.linalg.norm(prev - current))\n",
    "plt.plot(from_prev_l2norm_dists)\n",
    "plt.ylabel('L2-norm distance from each transition matrix from its previous one.')\n",
    "# seting xticks\n",
    "ax = plt.axes()\n",
    "number_of_periods = len(periods)\n",
    "ax.set_xticks(list(range(number_of_periods)))\n",
    "labels = ['[{}, {}] to [{}, {}]'.format(periods[i][0][:7], periods[i][1][:7], periods[i+1][0][:7], periods[i+1][1][:7]) for i in range(number_of_periods-1)]\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (60, 20)})\n",
    "acc_from_prev_l2norm_dists = []\n",
    "n = len(acc_result['transition_matrices'])\n",
    "for i in range(1, n):\n",
    "    current = acc_result['transition_matrices'][i]\n",
    "    prev = acc_result['transition_matrices'][i-1]\n",
    "    acc_from_prev_l2norm_dists.append(np.linalg.norm(prev - current))\n",
    "plt.plot(acc_from_prev_l2norm_dists)\n",
    "plt.ylabel('L2-norm distance from each transition matrix from its previous one.')\n",
    "# seting xticks\n",
    "ax = plt.axes()\n",
    "number_of_periods = len(periods)\n",
    "ax.set_xticks(list(range(number_of_periods)))\n",
    "labels = ['[{}, {}] to [{}, {}]'.format(periods[i][0][:7], periods[i][1][:7], periods[i+1][0][:7], periods[i+1][1][:7]) for i in range(number_of_periods-1)]\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitivity balance over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = 0\n",
    "transitive_balances = []\n",
    "for triad in triad_list:\n",
    "    bal = network_utils.is_sparsely_transitive_balanced(triad)\n",
    "    transitive_balances.append(bal)\n",
    "    if bal:\n",
    "        balanced += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Transitive balanced triads: ', balanced)\n",
    "print('Out of triads: ', len(triad_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVX Optimized Transitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitives = []\n",
    "for triad in triad_list:\n",
    "    transitives.append(network_utils.is_sparsely_transitive_balanced(triad))\n",
    "transitives = np.array(transitives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_matrix = M[l-1-1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.sum(trans_matrix[transitives, :][:, transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "plt.title(\n",
    "    'Transition probability of \"transitive to self\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "plt.show()\n",
    "\n",
    "probs = np.sum(trans_matrix[~transitives, :][:, transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "plt.title('Transition probability of \"not transitive to transitive\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "probs = np.sum(trans_matrix[~transitives, :][:, ~transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "plt.title('Transition probability of \"not transitive to self\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "plt.show()\n",
    "\n",
    "probs = np.sum(trans_matrix[transitives, :][:, ~transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "plt.title('Transition probability of \"transitive to not transitive\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.sum(trans_matrix[transitives, :][:, transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "print('Transition probability of \"transitive to self\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "\n",
    "probs = np.sum(trans_matrix[~transitives, :][:, transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "print('Transition probability of \"not transitive to transitive\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "\n",
    "probs = np.sum(trans_matrix[~transitives, :][:, ~transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "print('Transition probability of \"not transitive to self\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "\n",
    "probs = np.sum(trans_matrix[transitives, :][:, ~transitives], axis=1)\n",
    "plt.hist(probs)\n",
    "print('Transition probability of \"transitive to not transitive\": {} +- {}'.format(\n",
    "        round(np.mean(probs), 2), round(np.std(probs), 2)))\n",
    "\n",
    "plt.legend(['self transitive', 'nontransitive to transitive', 'self nontransitive', 'transitive to nontransitive']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_transitive_means = []\n",
    "self_nontransitive_means = []\n",
    "nontransitive_to_transitive_means = []\n",
    "transitive_to_nontransitive_means = []\n",
    "self_transitive_stds = []\n",
    "self_nontransitive_stds = []\n",
    "nontransitive_to_transitive_stds = []\n",
    "transitive_to_nontransitive_stds = []\n",
    "\n",
    "for matrix in M:\n",
    "    trans_matrix = matrix.value\n",
    "    \n",
    "    probs = np.sum(trans_matrix[transitives, :][:, transitives], axis=1)\n",
    "    self_transitive_means.append(np.mean(probs))\n",
    "    self_transitive_stds.append(np.std(probs))\n",
    "\n",
    "    probs = np.sum(trans_matrix[~transitives, :][:, transitives], axis=1)\n",
    "    nontransitive_to_transitive_means.append(np.mean(probs))\n",
    "    nontransitive_to_transitive_stds.append(np.std(probs))\n",
    "\n",
    "    probs = np.sum(trans_matrix[~transitives, :][:, ~transitives], axis=1)\n",
    "    transitive_to_nontransitive_means.append(np.mean(probs))\n",
    "    transitive_to_nontransitive_stds.append(np.std(probs))\n",
    "\n",
    "    probs = np.sum(trans_matrix[transitives, :][:, ~transitives], axis=1)\n",
    "    self_nontransitive_means.append(np.mean(probs))\n",
    "    self_nontransitive_stds.append(np.std(probs))\n",
    "    \n",
    "\n",
    "plt.errorbar(x=np.arange(l-1), y=self_transitive_means, yerr=self_transitive_stds, fmt='r')\n",
    "plt.errorbar(x=np.arange(l-1), y=nontransitive_to_transitive_means, yerr=nontransitive_to_transitive_stds, fmt='g')\n",
    "plt.errorbar(x=np.arange(l-1), y=self_nontransitive_means, yerr=self_nontransitive_stds, fmt='b')\n",
    "plt.errorbar(x=np.arange(l-1), y=transitive_to_nontransitive_means, yerr=transitive_to_nontransitive_stds, fmt='k')\n",
    "plt.legend(['self transitive', 'nontransitive to transitive', 'self nontransitive', 'transitive to nontransitive']);\n",
    "\n",
    "\n",
    "# plt.errorbar(x=np.arange(39), y=self_transitive_means) #, yerr=self_transitive_stds)\n",
    "# plt.errorbar(x=np.arange(39), y=nontransitive_to_transitive_means) #, yerr=nontransitive_to_transitive_stds)\n",
    "# plt.errorbar(x=np.arange(39), y=self_nontransitive_means) #, yerr=self_nontransitive_stds)\n",
    "# plt.errorbar(x=np.arange(39), y=transitive_to_nontransitive_means) #, yerr=transitive_to_nontransitive_stds)\n",
    "# plt.legend(['self transitive', 'nontransitive to transitive', 'self nontransitive', 'transitive to nontransitive']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (60, 20)})\n",
    "transitivity_balance = []\n",
    "for period_triads in result['triads_types']:\n",
    "    balanced = 0.0\n",
    "    for triad_index in period_triads.values():\n",
    "        if transitive_balances[triad_index]:\n",
    "            balanced += 1.0\n",
    "    balanced /= len(period_triads)\n",
    "    transitivity_balance.append(balanced)\n",
    "plt.plot(transitivity_balance)\n",
    "plt.ylabel('Transitivity Balance Ratio.')\n",
    "# seting xticks\n",
    "ax = plt.axes()\n",
    "number_of_periods = len(periods)\n",
    "ax.set_xticks(list(range(number_of_periods)))\n",
    "labels = ['[{}, {}]'.format(periods[i][0][:7], periods[i][1][:7]) for i in range(number_of_periods)]\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (60, 20)})\n",
    "acc_transitivity_balance = []\n",
    "for period_triads in acc_result['triads_types']:\n",
    "    balanced = 0.0\n",
    "    for triad_index in period_triads.values():\n",
    "        if transitive_balances[triad_index]:\n",
    "            balanced += 1.0\n",
    "    balanced /= len(period_triads)\n",
    "    acc_transitivity_balance.append(balanced)\n",
    "plt.plot(acc_transitivity_balance)\n",
    "plt.ylabel('Transitivity Balance Ratio.')\n",
    "# seting xticks\n",
    "ax = plt.axes()\n",
    "number_of_periods = len(periods)\n",
    "ax.set_xticks(list(range(number_of_periods)))\n",
    "labels = ['[{}, {}]'.format(periods[i][0][:7], periods[i][1][:7]) for i in range(number_of_periods)]\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Van De Rijt balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_balances = []\n",
    "for separate_dgraph in separate_dgraphs:\n",
    "    edge_balances.append(network_utils.compute_vanderijt_edge_balance(separate_dgraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_mean_balance = []\n",
    "for index, edge_balance in enumerate(edge_balances):\n",
    "    balanced_edges = list(np.ones(\n",
    "        len(set(separate_dgraphs[index].edges()) - set(edge_balance.keys()))))\n",
    "    network_mean_balance.append(\n",
    "        np.mean(balanced_edges + [item['#balanced_node3'] / item['#nodes3']\n",
    "                 for item in list(edge_balance.values())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(network_mean_balance)\n",
    "plt.ylabel('Average Edge Balance of Network.')\n",
    "# seting xticks\n",
    "ax = plt.axes()\n",
    "number_of_periods = len(periods)\n",
    "ax.set_xticks(list(range(number_of_periods)))\n",
    "labels = ['[{}, {}]'.format(periods[i][0][:7], periods[i][1][:7]) for i in range(number_of_periods)]\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_all_variables_of_current_session(locals(), '/local/home/student/omid55/sbt_data_saved/avg_all_vars.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
